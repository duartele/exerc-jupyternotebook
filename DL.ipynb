{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM03GPz7TYmq48aNZlUXekj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duartele/exerc-jupyternotebook/blob/main/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L-pRxu_dCZ9"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a network with 1 linear unit\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(units=1, input_shape=[3])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the first argument, units, we define how many outputs we want. In this case we are just predicting 'calories', so we'll use units=1.\n",
        "\n",
        "With the second argument, input_shape, we tell Keras the dimensions of the inputs. Setting input_shape=[3] ensures the model will accept three features as input ('sugars', 'fiber', and 'protein')."
      ],
      "metadata": {
        "id": "Pvjo6xWJd2u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # the hidden ReLU layers\n",
        "    layers.Dense(units=4, activation='relu', input_shape=[2]),\n",
        "    layers.Dense(units=3, activation='relu'),\n",
        "    # the linear output layer \n",
        "    layers.Dense(units=1),\n",
        "])"
      ],
      "metadata": {
        "id": "XSpNEa7zd8FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "layers.Dense(units=8),\n",
        "layers.Activation('relu')\n",
        "\n",
        "Is equivalent to\n",
        "layers.Dense(units=3, activation='relu')\n"
      ],
      "metadata": {
        "id": "jtl8c4ixgDiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Others activations 'relu' to 'elu', 'selu', 'swish'\n",
        "activation_layer = layers.Activation('relu')\n",
        "\n",
        "x = tf.linspace(-3.0, 3.0, 100)\n",
        "y = activation_layer(x) # once created, a layer is callable just like a function\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "plt.plot(x, y)\n",
        "plt.xlim(-3, 3)\n",
        "plt.xlabel(\"Input\")\n",
        "plt.ylabel(\"Output\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aof1rA18g4FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each iteration's sample of training data is called a minibatch (or often just \"batch\"), while a complete round of the training data is called an epoch. The number of epochs you train for is how many times the network will see each training example."
      ],
      "metadata": {
        "id": "1IzSOKvgPQTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"mae\",\n",
        ")"
      ],
      "metadata": {
        "id": "2OdB6O8TPPxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    batch_size=256,\n",
        "    epochs=10,\n",
        ")"
      ],
      "metadata": {
        "id": "ti5u8znLPw4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Often, a better way to view the loss though is to plot it. The fit method in fact keeps a record of the loss produced during training in a History object. We'll convert the data to a Pandas dataframe, which makes the plotting easy."
      ],
      "metadata": {
        "id": "_uiVg5qkRjwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# convert the training history to a dataframe\n",
        "history_df = pd.DataFrame(history.history)\n",
        "# use Pandas native plot method\n",
        "history_df['loss'].plot();"
      ],
      "metadata": {
        "id": "BuOxFksmRk5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "smaller batch sizes gave noisier weight updates and loss curves. This is because each batch is a small sample of data and smaller samples tend to give noisier estimates. Smaller batches can have an \"averaging\" effect though which can be beneficial.\n",
        "Smaller learning rates make the updates smaller and the training takes longer to converge. Large learning rates can speed up training, but don't \"settle in\" to a minimum as well."
      ],
      "metadata": {
        "id": "2HC_5XwlWAHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can increase the capacity of a network either by making it wider (more units to existing layers) or by making it deeper (adding more layers). Wider networks have an easier time learning more linear relationships, while deeper networks prefer more nonlinear ones. Which is better just depends on the dataset."
      ],
      "metadata": {
        "id": "epIUXuL-Xv9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q2JIwvNBRlXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "62AS92ScRldU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NYc54ZQnRliQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y9nTZx5pRlnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6IfnAExYRlsB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}