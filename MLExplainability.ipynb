{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLExplainability.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+z8z2X0R5KOAkXBC5VDyJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duartele/exerc-jupyternotebook/blob/main/MLExplainability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permutation Importance - change one column to verify how important that variable is."
      ],
      "metadata": {
        "id": "AtLMnPhiKurI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXAldsKTKdAs"
      },
      "outputs": [],
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n",
        "eli5.show_weights(perm, feature_names = val_X.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.describe()"
      ],
      "metadata": {
        "id": "GHQivfhOOnxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from pdpbox import pdp, get_dataset, info_plots"
      ],
      "metadata": {
        "id": "tmArws3NVHyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP Values\n",
        "We will look at SHAP values for a single row of the dataset (we arbitrarily chose row 5). For context, we'll look at the raw predictions before looking at the SHAP values."
      ],
      "metadata": {
        "id": "2PxK5RWOdk8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap  # package used to calculate Shap values\n",
        "\n",
        "# Create object that can calculate shap values\n",
        "explainer = shap.TreeExplainer(my_model)\n",
        "\n",
        "# Calculate Shap values\n",
        "shap_values = explainer.shap_values(data_for_prediction)"
      ],
      "metadata": {
        "id": "-bM7j2gQdkcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)"
      ],
      "metadata": {
        "id": "Z2WUb2lqev7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But the SHAP package has explainers for every type of model."
      ],
      "metadata": {
        "id": "RhHTmoX2fGrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.DeepExplainer #works with Deep Learning models\n",
        "shap.KernelExplainer #works with all models, though it is slower than other Explainers and it offers an approximation rather than exact Shap values.\n",
        "\n",
        "# use Kernel SHAP to explain test set predictions\n",
        "k_explainer = shap.KernelExplainer(my_model.predict_proba, train_X)\n",
        "k_shap_values = k_explainer.shap_values(data_for_prediction)\n",
        "shap.force_plot(k_explainer.expected_value[1], k_shap_values[1], data_for_prediction)"
      ],
      "metadata": {
        "id": "Pv1VYpBLdkYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap  # package used to calculate Shap values\n",
        "\n",
        "# Create object that can calculate shap values\n",
        "explainer = shap.TreeExplainer(my_model)\n",
        "\n",
        "# calculate shap values. This is what we will plot.\n",
        "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
        "shap_values = explainer.shap_values(val_X)\n",
        "\n",
        "# Make plot. Index of [1] is explained in text below.\n",
        "shap.summary_plot(shap_values[1], val_X)\n"
      ],
      "metadata": {
        "id": "MJthbJW1XOCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6aIJApaeXPOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}